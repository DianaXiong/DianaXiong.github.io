<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jianwei Guo | Weidan Xiong</title>
    <link>/authors/jianwei-guo/</link>
      <atom:link href="/authors/jianwei-guo/index.xml" rel="self" type="application/rss+xml" />
    <description>Jianwei Guo</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>XIONG WEIDANÂ©2025</copyright><lastBuildDate>Tue, 26 Aug 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Jianwei Guo</title>
      <link>/authors/jianwei-guo/</link>
    </image>
    
    <item>
      <title>Aerial Path Planning for Urban Geometry and Texture Co-Capture</title>
      <link>/project/dronetex/</link>
      <pubDate>Tue, 26 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/project/dronetex/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DiffTex: Differentiable Texturing for Architectural Proxy Models</title>
      <link>/project/difftex/</link>
      <pubDate>Tue, 26 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/project/difftex/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TwinTex: Geometry-aware Texture Generation for Abstracted 3D Architectural Models</title>
      <link>/project/twintex/</link>
      <pubDate>Sat, 05 Aug 2023 00:00:00 +0000</pubDate>
      <guid>/project/twintex/</guid>
      <description>&lt;p&gt;Coarse architectural models are often generated at scales ranging from individual buildings to scenes for downstream applications such as Digital Twin City, Metaverse, LODs, etc. Such piece-wise planar models can be abstracted as twins from 3D dense reconstructions. However, these models typically lack realistic texture relative to the real building or scene, making them unsuitable for vivid display or direct reference. In this paper, we present TwinTex, the first automatic texture mapping framework to generate a photo-realistic texture for a piece-wise planar proxy. Our method addresses most challenges occurring in such twin texture generation. Specifically, for each primitive plane, we first select a small set of photos with greedy heuristics considering photometric quality, perspective quality and facade texture completeness. Then, different levels of line features (LoLs) are extracted from the set of selected photos to generate guidance for later steps. With LoLs, we employ optimization algorithms to align texture with geometry from local to global. Finally, we fine-tune a diffusion model with a multi-mask initialization component and a new dataset to inpaint the missing region. Experimental results on many buildings, indoor scenes and man-made objects of varying complexity demonstrate the generalization ability of our algorithm. Our approach surpasses state-of-the-art texture mapping methods in terms of high-fidelity quality and reaches a human-expert production level with much less effort.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
